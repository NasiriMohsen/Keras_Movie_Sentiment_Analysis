{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP Libraries: NLTK, Enchant, Spacy, and Regex\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import words as realwords\n",
    "import enchant\n",
    "import spacy\n",
    "import re\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model related libraries: Tensorflow, Keras, and Sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essentials libraries\n",
    "import pandas as pd \n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "import kagglehub\n",
    "from IPython.display import clear_output\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "warnings.filterwarnings(\"ignore\", category = DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model variables\n",
    "vocab_size = 20000\n",
    "max_len = 100\n",
    "learning_rate = 0.00075\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "preproccesing_batch_size = 2000\n",
    "dataset_split = 0.03666 #0.073323"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path variables\n",
    "model_path = '131k.keras'\n",
    "model_history_path = '131k_history.json'\n",
    "tokenizer_path = '131k.pickle'\n",
    "\n",
    "main_dataset_path = '136k_dataset.csv'\n",
    "\n",
    "custom_imdb_data_path = 'Custome_IMDB_data.csv'\n",
    "rotten_tomatoes_data_path = 'Rotton_Tomatoes_data.csv'\n",
    "imdb_data_path = 'Stanford_IMDB_data.csv'\n",
    "sst2_data_path = 'Stanford_SST2_data.csv'\n",
    "arize_data_path = 'Arize_data.csv'\n",
    "\n",
    "dataset_files = [\n",
    "    {'variable_names': 'stanford_imdb_train', 'path': 'datasets_raw/Stanford_IMDB_train.csv', 'url': \"hf://datasets/stanfordnlp/imdb/plain_text/train-00000-of-00001.parquet\"},\n",
    "    {'variable_names': 'stanford_imdb_validation', 'path': 'datasets_raw/Stanford_IMDB_validation.csv', 'url': \"hf://datasets/stanfordnlp/imdb/plain_text/test-00000-of-00001.parquet\"},\n",
    "    {'variable_names': 'stanford_sst2_train', 'path': 'datasets_raw/SST2_train.csv', 'url': \"hf://datasets/stanfordnlp/sst2/data/train-00000-of-00001.parquet\"},\n",
    "    {'variable_names': 'stanford_sst2_validation', 'path': 'datasets_raw/SST2_validation.csv', 'url': \"hf://datasets/stanfordnlp/sst2/data/validation-00000-of-00001.parquet\"},\n",
    "    {'variable_names': 'rotten_tomatoes_train', 'path': 'datasets_raw/Rotten_Tomatoes__train.csv', 'url': \"hf://datasets/cornell-movie-review-data/rotten_tomatoes/train.parquet\"},\n",
    "    {'variable_names': 'rotten_tomatoes_validation', 'path': 'datasets_raw/Rotten_Tomatoes_validation.csv', 'url': \"hf://datasets/cornell-movie-review-data/rotten_tomatoes/validation.parquet\"},\n",
    "    {'variable_names': 'rotten_tomatoes_test', 'path': 'datasets_raw/Rotten_Tomatoes_test.csv', 'url': \"hf://datasets/cornell-movie-review-data/rotten_tomatoes/test.parquet\"},\n",
    "    {'variable_names': 'arize_train', 'path': 'datasets_raw/Arize_train.csv', 'url': \"hf://datasets/arize-ai/movie_reviews_with_context_drift/validation.csv\"},\n",
    "    {'variable_names': 'arize_validation', 'path': 'datasets_raw/Arize_validation.csv', 'url': \"hf://datasets/arize-ai/movie_reviews_with_context_drift/training.csv\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text processing variables\n",
    "html_tag_pattern = re.compile(r'<.*?>')\n",
    "words_to_keep = {\n",
    "    'not', 'never', 'no', 'none', 'cannot', 'without', 'neither', 'nor', 'hardly', 'barely', 'rarely', \n",
    "    'nothing', 'but', 'although', 'however', 'yet', 'though', 'nonetheless', 'despite', 'still', 'whereas', \n",
    "    'even though', 'on the other hand', 'very', 'so', 'really', 'absolutely', 'incredibly', 'especially', \n",
    "    'extremely', 'particularly', 'quite', 'definitely', 'indeed', 'nobody', 'nowhere', 'scarcely', 'because', \n",
    "    'if', 'unless', 'since', 'thus', 'therefore', 'instead', 'moreover', 'besides', 'furthermore', 'above', \n",
    "    'again', 'below', 'down', 'further', 'few', 'just', 'more', 'off', 'need', 'would', 'will', 'through', \n",
    "    'under', 'until', 'up', 'while', 'won', 'about', 'after', 'could', 'into', 'now', 'of', 'on', 'once', \n",
    "    'only', 'other', 'out', 'over', 'own', 'should', 'some', 'too', 'what', 'why', 'against',\n",
    "    'can', 'do', 'have', 'how', 'most', 'same', 'such', 'when', 'where', 'which', 'who', 'whom', 'with',\n",
    "}\n",
    "stop_words = set(stopwords.words('english')) - words_to_keep\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "entity_types = {'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'MONEY', 'NORP', 'PERSON', 'PRODUCT', 'TIME'}\n",
    "real_words = set(realwords.words())\n",
    "Word_Dict = enchant.Dict(\"en_US\")\n",
    "nlp = spacy.load(\"en_core_web_lg\",disable = ['ner', 'parser'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process text\n",
    "def process_text(text):\n",
    "    doc = nlp(re.sub(html_tag_pattern, '', text))\n",
    "    words = [word.lemma_.lower() for word in doc if word.is_alpha and (word.lemma_.lower() not in stop_words and len(word.lemma_.lower()) > 2) or word.lemma_.lower() in words_to_keep]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for batch processing texts \n",
    "def batch_process_texts(texts):\n",
    "    processed_texts, counter = [], 0\n",
    "    for doc in nlp.pipe((re.sub(html_tag_pattern, '', text) for text in texts), batch_size = preproccesing_batch_size):\n",
    "        words = []\n",
    "        counter += 1\n",
    "        if counter % 20 == 0: print(counter)\n",
    "        for word in doc:\n",
    "            lemma = word.lemma_.lower()\n",
    "            if word.is_alpha and (lemma not in stop_words and len(lemma) > 2) or lemma in words_to_keep:\n",
    "                words.append(lemma)\n",
    "        processed_texts.append(\" \".join(words))\n",
    "    return processed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for loading datasets\n",
    "def load_datasets():\n",
    "    os.makedirs('datasets_raw/', exist_ok = True)\n",
    "    os.makedirs('datasets_processed/', exist_ok = True)\n",
    "    for dataset_file in dataset_files:\n",
    "        if os.path.exists(dataset_file['path']):\n",
    "            globals()[dataset_file['variable_names']] = pd.read_csv(dataset_file['path'])\n",
    "            print(f\"\\x1b[32m {dataset_file['variable_names']} has been loaded! \\x1b[0m\")\n",
    "        else:\n",
    "            print(f\"\\x1b[31m {dataset_file['variable_names']} is downloading! \\x1b[0m\")\n",
    "            if dataset_file['url'].endswith('.csv'):\n",
    "                globals()[dataset_file['variable_names']] = pd.read_csv(dataset_file['url'])\n",
    "            else:\n",
    "                globals()[dataset_file['variable_names']] = pd.read_parquet(dataset_file['url'])\n",
    "            globals()[dataset_file['variable_names']].to_csv(dataset_file['path'], index = False)\n",
    "            print(f\"\\x1b[32m {dataset_file['variable_names']} has been loaded! \\x1b[0m\")   \n",
    "    if os.path.exists('datasets_raw/Custom.csv'):\n",
    "        custom_dataset = pd.read_csv('datasets_raw/Custom.csv')\n",
    "        print(f\"\\x1b[32m custom has been loaded! \\x1b[0m\")   \n",
    "    else:\n",
    "        print(f\"\\x1b[31m custom is downloading! \\x1b[0m\")\n",
    "        path = kagglehub.dataset_download(\"itsabba3/imdb-rating\")\n",
    "        custom_dataset = pd.read_csv(os.path.join(path, os.listdir(path)[0]))\n",
    "        custom_dataset.to_csv('datasets_raw/Custom.csv', index = False)\n",
    "        print(f\"\\x1b[32m custom has been loaded! \\x1b[0m\")  \n",
    "    if os.path.exists('datasets_processed/' + rotten_tomatoes_data_path):\n",
    "        rotten_tomatoes_data = pd.read_csv('datasets_processed/' + rotten_tomatoes_data_path)\n",
    "        print(f\"\\x1b[32m rotten_tomatoes_data has been loaded! \\x1b[0m\")\n",
    "    else:\n",
    "        print(f\"\\x1b[31m rotten_tomatoes_data is processing! \\x1b[0m\")\n",
    "        rotten_tomatoes_data = pd.concat([rotten_tomatoes_train, rotten_tomatoes_validation, rotten_tomatoes_test])\n",
    "        rotten_tomatoes_data.columns = ['review', 'rate'] + rotten_tomatoes_data.columns.tolist()[2:]\n",
    "        rotten_tomatoes_data = rotten_tomatoes_data.drop_duplicates()\n",
    "        #rotten_tomatoes_data['review'] = rotten_tomatoes_data['review'].map(process_text)\n",
    "        rotten_tomatoes_data['review'] = batch_process_texts(rotten_tomatoes_data['review'].tolist())\n",
    "        rotten_tomatoes_data = rotten_tomatoes_data.dropna()\n",
    "        rotten_tomatoes_data.to_csv(\"datasets_processed/\" + rotten_tomatoes_data_path, index = False)\n",
    "        print(f\"\\x1b[32m rotten_tomatoes_data has been loaded! \\x1b[0m\")\n",
    "    if os.path.exists('datasets_processed/' + imdb_data_path):\n",
    "        stanford_imdb_data = pd.read_csv('datasets_processed/' + imdb_data_path)\n",
    "        print(f\"\\x1b[32m stanford_imdb_data has been loaded! \\x1b[0m\")\n",
    "    else:\n",
    "        print(f\"\\x1b[31m stanford_imdb_data is processing! \\x1b[0m\")\n",
    "        stanford_imdb_data = pd.concat([stanford_imdb_train, stanford_imdb_validation])\n",
    "        stanford_imdb_data.columns = ['review', 'rate'] + stanford_imdb_data.columns.tolist()[2:]\n",
    "        stanford_imdb_data = stanford_imdb_data.drop_duplicates()\n",
    "        #stanford_imdb_data['review'] = stanford_imdb_data['review'].map(process_text)\n",
    "        stanford_imdb_data['review'] = batch_process_texts(stanford_imdb_data['review'].tolist())\n",
    "        stanford_imdb_data = stanford_imdb_data.dropna()\n",
    "        stanford_imdb_data.to_csv(\"datasets_processed/\" + imdb_data_path, index = False)\n",
    "        print(f\"\\x1b[32m stanford_imdb_data has been loaded! \\x1b[0m\")\n",
    "    if os.path.exists('datasets_processed/' + sst2_data_path):\n",
    "        stanford_sst2_data = pd.read_csv('datasets_processed/' + sst2_data_path)\n",
    "        print(f\"\\x1b[32m sst2_data has been loaded! \\x1b[0m\")\n",
    "    else:\n",
    "        print(f\"\\x1b[31m sst2_data is processing! \\x1b[0m\")\n",
    "        stanford_sst2_data = pd.concat([stanford_sst2_train, stanford_sst2_validation])\n",
    "        stanford_sst2_data = stanford_sst2_data.drop(columns=['idx'])\n",
    "        stanford_sst2_data.columns = ['review', 'rate'] + stanford_sst2_data.columns.tolist()[2:]\n",
    "        stanford_sst2_data = stanford_sst2_data.drop_duplicates()\n",
    "        #stanford_sst2_data['review'] = stanford_sst2_data['review'].map(process_text)\n",
    "        stanford_sst2_data['review'] = batch_process_texts(stanford_sst2_data['review'].tolist())\n",
    "        stanford_sst2_data = stanford_sst2_data.dropna()\n",
    "        stanford_sst2_data.to_csv(\"datasets_processed/\" + sst2_data_path, index = False)\n",
    "        print(f\"\\x1b[32m sst2_data has been loaded! \\x1b[0m\")\n",
    "    if os.path.exists('datasets_processed/' + arize_data_path):\n",
    "        arize_data = pd.read_csv('datasets_processed/' + arize_data_path)\n",
    "        print(f\"\\x1b[32m arize_data has been loaded! \\x1b[0m\")\n",
    "    else:\n",
    "        print(f\"\\x1b[31m arize_data is processing! \\x1b[0m\")\n",
    "        arize_data = pd.concat([arize_validation, arize_train])\n",
    "        arize_data = arize_data[[\"text\",\"label\"]]\n",
    "        arize_data.columns = ['review', 'rate'] + arize_data.columns.tolist()[2:]\n",
    "        arize_data['rate'] = arize_data['rate'].replace({'negative': 0, 'positive': 1})\n",
    "        arize_data = arize_data.drop_duplicates()\n",
    "        #arize_data['review'] = arize_data['review'].map(process_text)\n",
    "        arize_data['review'] = batch_process_texts(arize_data['review'].tolist())\n",
    "        arize_data = arize_data.dropna()\n",
    "        arize_data.to_csv(\"datasets_processed/\" + arize_data_path, index = False)\n",
    "        print(f\"\\x1b[32m arize_data has been loaded! \\x1b[0m\")\n",
    "    if os.path.exists('datasets_processed/' + custom_imdb_data_path):\n",
    "        custom_data = pd.read_csv('datasets_processed/' + custom_imdb_data_path)\n",
    "        print(f\"\\x1b[32m custom_data has been loaded! \\x1b[0m\")\n",
    "    else:\n",
    "        print(f\"\\x1b[31m custom_data is processing! \\x1b[0m\")\n",
    "        custom_data = custom_dataset.drop(columns=['Movie_ID'])\n",
    "        custom_data.columns = ['review', 'rate'] + custom_data.columns.tolist()[2:]\n",
    "        custom_data['rate'] = custom_data['rate'].apply(lambda x: 0 if 1 <= x <= 3 else 1 if 8 <= x <= 10 else None)\n",
    "        custom_data = custom_data.dropna(subset=['rate'])\n",
    "        custom_data = custom_data.drop_duplicates()\n",
    "        #custom_data['review'] = custom_data['review'].map(process_text)\n",
    "        custom_data['review'] = batch_process_texts(custom_data['review'].tolist())\n",
    "        custom_data = custom_data.dropna()\n",
    "        custom_data.to_csv('datasets_processed/' + custom_imdb_data_path, index = False)\n",
    "        print(f\"\\x1b[32m custom_data has been loaded! \\x1b[0m\")\n",
    "    if os.path.exists('datasets_processed/' + main_dataset_path):\n",
    "        all_data = pd.read_csv('datasets_processed/' + main_dataset_path)\n",
    "        print(f\"\\x1b[32m {main_dataset_path} has been loaded! \\x1b[0m\")\n",
    "    else:\n",
    "        print(f\"\\x1b[31m {main_dataset_path} is processing! \\x1b[0m\")\n",
    "        all_data = pd.concat([stanford_imdb_data, stanford_sst2_data, rotten_tomatoes_data, arize_data, custom_data])\n",
    "        all_data = all_data.dropna()\n",
    "        all_data = all_data.groupby('rate').apply(lambda x: x.sample(all_data[\"rate\"].value_counts().min())).reset_index(drop = True)\n",
    "        all_data = all_data.sample(frac = 1, random_state = 42).reset_index(drop = True)\n",
    "        all_data.to_csv(\"datasets_processed/\" + main_dataset_path, index = False)\n",
    "        print(f\"\\x1b[32m {main_dataset_path} has been loaded! \\x1b[0m\")\n",
    "    train, test = train_test_split(all_data, test_size = dataset_split, random_state = 42)\n",
    "    return all_data, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for loading the tokenizer \n",
    "def load_tokenizer(dataset):\n",
    "    if os.path.exists(tokenizer_path):\n",
    "        with open(tokenizer_path, 'rb') as handle:\n",
    "            tokenizer = pickle.load(handle)\n",
    "        print(f\"\\x1b[32m tokenizer has been loaded! \\x1b[0m\")\n",
    "    else:\n",
    "        print(f\"\\x1b[31m tokenizer is being created! \\x1b[0m\")\n",
    "        tokenizer = Tokenizer(num_words = vocab_size)\n",
    "        tokenizer.fit_on_texts(dataset['review'])\n",
    "        word_counts = tokenizer.word_counts\n",
    "        words = set(word_counts.items())\n",
    "        words_to_remove, keep, named_entity_words = set(), set(), []\n",
    "        for word in words:\n",
    "            scores = sid.polarity_scores(word[0])\n",
    "            if scores['compound'] != 0 or word[0] in words_to_keep:\n",
    "                keep.add(word)\n",
    "            elif not bool(wordnet.synsets(word[0])) and not Word_Dict.check(word[0]) and not word[0] in real_words or word[1] <= 2:\n",
    "                words_to_remove.add(word) \n",
    "        words = list(words - words_to_remove -  keep)\n",
    "        nlp = spacy.load(\"en_core_web_lg\", disable = ['parser'])\n",
    "        docs = nlp.pipe((word[0] for word in words), batch_size = preproccesing_batch_size)\n",
    "        for i, doc in enumerate(docs):\n",
    "            if any(ent.label_ in entity_types for ent in doc.ents):\n",
    "                named_entity_words.append(words[i])\n",
    "        words = set(words) - set(named_entity_words)\n",
    "        words = words | keep\n",
    "        words = sorted(words, key = lambda x: x[1], reverse = True)[:vocab_size]\n",
    "        tokenizer.word_counts = dict(words)\n",
    "        with open(tokenizer_path, 'wb') as handle:\n",
    "            pickle.dump(tokenizer, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "        print(f\"\\x1b[32m tokenizer has been loaded! \\x1b[0m\")\n",
    "    y_train = np.array(dataset['rate'].values)\n",
    "    x_train = pad_sequences(tokenizer.texts_to_sequences(dataset['review']), maxlen = max_len, padding='post')\n",
    "    return tokenizer, x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for loading the model\n",
    "def load_model(tokenizer,x_train, y_train, x_val, y_val):\n",
    "    if os.path.exists(model_path):\n",
    "        model = tf.keras.models.load_model(model_path, compile = False, safe_mode = False)\n",
    "        with open(model_history_path, 'r') as file:\n",
    "            history = json.load(file)\n",
    "        print(f\"\\x1b[32m model has been loaded! \\x1b[0m\")\n",
    "    else:\n",
    "        print(f\"\\x1b[31m model is being created! \\x1b[0m\")\n",
    "        model = Sequential([\n",
    "            Embedding(input_dim = tokenizer.num_words, output_dim = 128),\n",
    "            SpatialDropout1D(rate = 0.3),\n",
    "            Bidirectional(LSTM(units = 128, return_sequences = False)),\n",
    "            Dropout(0.5),\n",
    "            Dense(units = 1, activation = 'sigmoid')\n",
    "        ])\n",
    "        model.compile(loss = 'binary_crossentropy', optimizer = Nadam(learning_rate = learning_rate), metrics = ['accuracy'])\n",
    "        history = model.fit(x_train, y_train, epochs = epochs, batch_size = batch_size, validation_data = (x_val, y_val))\n",
    "        with open(model_history_path, 'w') as file:\n",
    "            json.dump(history.history, file)\n",
    "        loss, accuracy = model.evaluate(x_train, y_train)\n",
    "        print(f\"Test Loss: {round(loss,4)}, Test Accuracy: {round(accuracy)}\")\n",
    "        model.summary()\n",
    "        model.save(model_path)\n",
    "        history = history.history\n",
    "        print(f\"\\x1b[32m model has been loaded! \\x1b[0m\")\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for visualizing the model history\n",
    "def model_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.plot(history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model valdiation function\n",
    "def model_validation(model, tokenizer, dataset):\n",
    "    print(\"\\x1b[32m model is being validated! \\x1b[0m\")\n",
    "    labels = np.array(dataset['rate'].values)\n",
    "    features = pad_sequences(tokenizer.texts_to_sequences(dataset['review']), maxlen = max_len, padding='post')\n",
    "    predecited_labels = (model.predict(features) > 0.5).astype(\"int32\")\n",
    "    print(\"Accuracy: {:.2f}%\".format(accuracy_score(labels, predecited_labels) * 100))\n",
    "    print(\"Precision: {:.2f}%\".format(precision_score(labels, predecited_labels) * 100))\n",
    "    print(\"Recall: {:.2f}%\".format(recall_score(labels, predecited_labels) * 100))\n",
    "    print(\"F1-Score: {:.2f}%\".format(f1_score(labels, predecited_labels) * 100))\n",
    "    cm = confusion_matrix(labels, predecited_labels)\n",
    "    plt.figure(figsize = (8, 6))\n",
    "    sns.heatmap(cm, annot = True, fmt = 'd', cmap = 'RdYlGn')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "    return labels, predecited_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorrect predictions visualization function  \n",
    "def incorrect_predictions(dataset, labels, predecited_labels):\n",
    "    wrong_indices = np.where(labels != predecited_labels.flatten())[0]\n",
    "    wrong_predictions = dataset.iloc[wrong_indices].copy()\n",
    "    print(f\"\\x1b[31m {len(wrong_predictions)} incorrect predictions! \\x1b[0m\")\n",
    "    for review in wrong_predictions['review']:\n",
    "        print(review)\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking non trained words in the input \n",
    "def is_word_trained(text,tokenizer):\n",
    "    for word in text.split(\" \"):\n",
    "        if word not in tokenizer.word_counts:\n",
    "            print(f'\\x1b[31m \"{word}\" is not in our data! \\x1b[0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human validation function\n",
    "def predict_sentiment(model, tokenizer):\n",
    "    clear_output(wait = True)\n",
    "    response = input(\"\\x1b[36m Enter the movie review to recive the sentiment of it: \\x1b[0m\\n\")\n",
    "    print(\"\\x1b[36m Input: \\x1b[0m\\n \", response)\n",
    "    new_review = process_text(response)\n",
    "    is_word_trained(new_review, tokenizer)\n",
    "    new_sequence = pad_sequences(tokenizer.texts_to_sequences([new_review]), maxlen = max_len, padding = 'post')\n",
    "    prediction = model.predict(new_sequence)[0][0]\n",
    "    print(\"\\x1b[36m Input processed: \\x1b[0m\\n \", new_review)\n",
    "    print(f\"\\x1b[36m The prediction is \\x1b[33m {round(prediction*100, 2)}\\x1b[36m and the sentiment of the movie review is: \\x1b[0m\", \"\\x1b[32mPositive \\x1b[0m\" if prediction > 0.5 else \"\\x1b[31mNegative \\x1b[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets setup\n",
    "all_data, dataset, validation_dataset = load_datasets()\n",
    "print(f\"\\x1b[33m The whole dataset shape is: \\x1b[0m{all_data.shape}\")\n",
    "print(f\"\\x1b[33m The training dataset shape is: \\x1b[0m{dataset.shape}\")\n",
    "print(f\"\\x1b[33m The validation dataset shape is: \\x1b[0m{validation_dataset.shape}\")\n",
    "tokenizer, x_train, y_train = load_tokenizer(dataset)\n",
    "y_val = np.array(validation_dataset['rate'].values)\n",
    "x_val = pad_sequences(tokenizer.texts_to_sequences(validation_dataset['review']), maxlen = max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model setup\n",
    "model, history = load_model(tokenizer, x_train, y_train, x_val, y_val)\n",
    "model_history(history)\n",
    "validation_labels, validation_predecited_labels = model_validation(model, tokenizer,  validation_dataset)\n",
    "incorrect_predictions(validation_dataset, validation_labels, validation_predecited_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop\n",
    "while True:\n",
    "    predict_sentiment(model, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
